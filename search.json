[
  {
    "objectID": "mm/mm.html",
    "href": "mm/mm.html",
    "title": "Appendix C — Mind Maps",
    "section": "",
    "text": "Creativity",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  },
  {
    "objectID": "mm/mm.html#creativity",
    "href": "mm/mm.html#creativity",
    "title": "Appendix C — Mind Maps",
    "section": "",
    "text": "0905-mind_map_.jpeg\n\n\n\n\n\n0912-mind_map_.jpeg\n\n\n\n\n\n0917-mind_map_.jpeg\n\n\n\n\n\n0922-mind_map_.jpeg\n\n\n\n\n\n0928-mind_map_.jpeg\n\n\n\n\n\n0930-mind_map_.jpeg\n\n\n\n\n\n1003-mind_map_.jpeg",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT212 Portfolio",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "src/pv/pv-01.html",
    "href": "src/pv/pv-01.html",
    "title": "Professional Viz Sample",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Prof Viz",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Professional Viz Sample</span>"
    ]
  },
  {
    "objectID": "homeworks/hw1_files/hw1.html",
    "href": "homeworks/hw1_files/hw1.html",
    "title": "hw1",
    "section": "",
    "text": "Research Question: How did home game attendance for the Detroit Lions change over the course of their best (2014) and worst (2008) seasons?\n\nCode# Get the Data\n\nattendance &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/attendance.csv')\nstandings &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/standings.csv')\ngames &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/games.csv')\n\n# Or read in with tidytuesdayR package (https://github.com/dslc-io/tidytuesdayR)\n# PLEASE NOTE TO USE 2020 DATA YOU NEED TO UPDATE tidytuesdayR from GitHub\n\n# Either ISO-8601 date or year/week works!\n\n# Install via pak::pak(\"dslc-io/tidytuesdayR\")\n\ntuesdata &lt;- tidytuesdayR::tt_load('2020-02-04') \ntuesdata &lt;- tidytuesdayR::tt_load(2020, week = 6)\n\n\nattendance &lt;- tuesdata$attendance\n\n\n\nCodelibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\n# filtering attendance and standings data so we only have data on detroit lions\nlions_attendance &lt;- attendance %&gt;%\n  filter(team == \"Detroit\")\n\nlions_standings &lt;- standings %&gt;%\n  filter(team == \"Detroit\")\n\n# filtering new attendance and standings data so it only includes their best (2014) and worst (2008) seasons\nlions_best_worst_seasons &lt;- lions_standings %&gt;%\n  filter(year == 2008 | year == 2014)\nlions_best_worst_attendance &lt;- lions_attendance %&gt;%\n  filter(year == 2008 | year == 2014)\n\n# filtering games data to only include lions home games\ngames &lt;- games %&gt;%\n  filter(home_team_name == \"Lions\")\n\n# filtering new games data to only include 2008 and 2014\ngames &lt;- games %&gt;%\n  filter(year == 2008 | year == 2014)\n\n# filtering out non home game data from standings and attendance dataset\nlions_best_attendance &lt;- lions_best_worst_attendance %&gt;%\n   filter(year == 2014)\nlions_worst_attendance &lt;- lions_best_worst_attendance %&gt;%\n   filter(year == 2008)\nlions_best_attendance &lt;- lions_best_attendance %&gt;%\n   filter(week %in% c(1,3,5,7,10,13,14,15))\nlions_worst_attendance &lt;- lions_worst_attendance %&gt;%\n   filter(week %in% c(2,5,8,10,12,13,14,16))\n\n# code for best / worst seasons total home game attendance\nbest_season_att &lt;- lions_best_attendance %&gt;%\n  select(year, home) %&gt;%\n  group_by(year) %&gt;%\n  summarise(total_attendance = sum(home))\nworst_season_att &lt;- lions_worst_attendance %&gt;%\n  select(year, home) %&gt;%\n  group_by(year) %&gt;%\n  summarise(total_attendance = sum(home))\n\n\n\nCode# visualizations to answer research question\n\nggplot() +\n  geom_col(data = best_season_att, \n           aes(x = factor(year), y = total_attendance), \n           fill = \"steelblue\") +\n  geom_col(data = worst_season_att, \n           aes(x = factor(year), y = total_attendance), \n           fill = \"gray\") +\n  scale_y_continuous(labels = comma) +\n  theme_classic() +\n  labs(\n    title = \"Detroit Lions Home Attendance\",\n    subtitle = \"Total home attendance across the best (2014) and worst (2008) season\",\n    x = \"Season\",\n    y = \"Total Home Attendance\"\n  )\n\n\n\n\n\n\nCodeggplot(lions_best_attendance, aes(x = week, y = weekly_attendance)) +\n  geom_line(color = \"steelblue\", linewidth = 1.2) +\n  geom_point(color = \"black\") +\n  theme_classic() +\n  labs(\n    title = \"Detroit Lions Home Game Attendance (Best Season (11-5))\",\n    subtitle = \"Weekly home attendance across the season\",\n    x = \"Week of Season\",\n    y = \"Attendance\"\n  )\n\n\n\n\n\n\nCodeggplot(lions_worst_attendance, aes(x = week, y = weekly_attendance)) +\n  geom_line(color = \"gray\", linewidth = 1.2) +\n  geom_point(color = \"black\") +\n  theme_classic() +\n  labs(\n    title = \"Detroit Lions Home Game Attendance (Worst Season (0-16))\",\n    subtitle = \"Weekly home attendance across the season\",\n    x = \"Week of Season\",\n    y = \"Attendance\"\n  )\n\n\n\n\n\n\n\n# The visualizations shown above demonstrate that the Detroit Lions had more home game attendees in the 2014 season when they went 11-5 than they did in their worst season, in which they lost all 16 of their games. The line graphs represent the week-by-week home game attendees for their best and worst seasons. Those visualizations demonstrate that during the 0 win season, attendance gradually decreased until week 12 and saw an abrupt increase and decrease in the coming weeks. In the winning season, attendance was larger all throughout the season, but saw the same decreases during different parts. During the middle chunk of the season (weeks 3-13) there was a gradual increase that was not seen during the losing season.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>hw1</span>"
    ]
  },
  {
    "objectID": "src/ica/16-databases-notes.html",
    "href": "src/ica/16-databases-notes.html",
    "title": "16 Databases and SQL",
    "section": "",
    "text": "🧩 Learning Goals\nBy the end of this lesson, you should be able to: - Develop comfort in composing SQL queries - See the connections between tidyverse verbs and SQL clauses",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>16 Databases and SQL</span>"
    ]
  },
  {
    "objectID": "src/ica/16-databases-notes.html#introduction",
    "href": "src/ica/16-databases-notes.html#introduction",
    "title": "16 Databases and SQL",
    "section": "Introduction",
    "text": "Introduction\nIf you find yourself analyzing data within a medium or large organization, you will probably draw on data stored within a centralized data warehouse.\nData warehouses contain vast collections of information–far more than a desktop or laptop computer can easily analyze.\nThese warehouses typically rely on structured data repositories called relational databases (also often called SQL databases).\nRelational databases store data in tables, which are structured with rows and columns (attributes). Tables can be joined using keys which uniquely identify a row within a table.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>16 Databases and SQL</span>"
    ]
  },
  {
    "objectID": "src/ica/16-databases-notes.html#connecting-to-a-database-in-r-with-dbi",
    "href": "src/ica/16-databases-notes.html#connecting-to-a-database-in-r-with-dbi",
    "title": "16 Databases and SQL",
    "section": "Connecting to a database in R with DBI\n",
    "text": "Connecting to a database in R with DBI\n\nThe DBI package (database interface) provides general tools for interacting with databases from R.\n\nIt is also common for data scientists to interact with databases directly by writing SQL queries. We’ll talk about this in the next section.\n\nFor now, we’ll use DBI to connect with an in-process database (duckdb), one that runs locally on your computer.\n\nA nice feature of duckdb is that even if your dataset is huge, duckdb can work with it very quickly.\n\nWe can set up a database connection with dbConnect() and initialize a temporary database with duckdb():\n\nCodecon &lt;- DBI::dbConnect(duckdb::duckdb())\nclass(con)\n\n[1] \"duckdb_connection\"\nattr(,\"package\")\n[1] \"duckdb\"\n\n\nIn a real project, we would use duckdb_read_csv() to store data directly into the duckdb database without first having to read it into R.\nIn the toy example below, we have a dataset on Spotify songs (all_spotify_songs.csv) and store in a database table called \"songs\":\n\nCodeduckdb_read_csv(con, \"songs\", \"https://hash-mac.github.io/stat212site-f25/relative/path/to/all_spotify_songs.csv\")\n\n\nHere, we’ll use datasets from the nycflights13 package.\nThe DBI package provides the dbWriteTable() function to write dataset objects (in constrast to csv files) to a database:\n\nCodedbWriteTable(con, \"flights\", nycflights13::flights)\ndbWriteTable(con, \"planes\", nycflights13::planes)\n\n\nWe can use tbl(), short for table, to create connections individually to the flights and planes datasets.\n\nCodeflights &lt;- tbl(con, \"flights\")\nplanes &lt;- tbl(con, \"planes\")\n\n\nNote that the results of tbl() are not quite the same as our normal data frames.\nAlthough they have class tbl, note that the number of rows is NA!\nThe full dataset isn’t loaded into memory when we use tbl, so the number of rows is unknown. This behavior is purposeful–it reduces computer resources and allows access to parts of the data only when needed.\n\nCodeclass(flights)\n\n[1] \"tbl_duckdb_connection\" \"tbl_dbi\"               \"tbl_sql\"              \n[4] \"tbl_lazy\"              \"tbl\"                  \n\nCodedim(flights)\n\n[1] NA 19",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>16 Databases and SQL</span>"
    ]
  },
  {
    "objectID": "src/ica/16-databases-notes.html#what-is-sql",
    "href": "src/ica/16-databases-notes.html#what-is-sql",
    "title": "16 Databases and SQL",
    "section": "What is SQL?",
    "text": "What is SQL?\nSQL stands for Structured Query Language.\nIt is a programming language to query or retrieve data from a relational database.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>16 Databases and SQL</span>"
    ]
  },
  {
    "objectID": "src/ica/16-databases-notes.html#sql-with-dplyr",
    "href": "src/ica/16-databases-notes.html#sql-with-dplyr",
    "title": "16 Databases and SQL",
    "section": "SQL with dplyr\n",
    "text": "SQL with dplyr\n\nA really nice feature of dplyr is that we can write R code for wrangling the data and use show_query() to translate that code into SQL.\n\nCodeflights |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT *\nFROM flights\n\nCodeflights |&gt;\n    mutate(full_date = str_c(year, month, day, sep = \"-\")) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT flights.*, CONCAT_WS('-', \"year\", \"month\", \"day\") AS full_date\nFROM flights\n\n\nExplore: Create a Google Document and share it with the people at your table. Using the code examples below, work with your group to co-create a dplyr&lt;-&gt; SQL translation guide (notes document) that allows you to answer the following:\n\nWhat do SELECT, FROM, WHERE, GROUP BY, and ORDER BY in SQL do? (These uppercase words are called clauses in SQL.)\n\nHow do these clauses translate to the main tidyverse verbs select, mutate, filter, arrange, summarize, group_by?\n\n\nWhat syntax differences are there for logical comparisons?\n\nHow do the & and | logical operators in R compare to SQL?\n\n\nHow does the R syntax for mutate translate to SQL?\nHow does joining datasets seem to work in SQL?\n\n\nCodeflights |&gt; \n    filter(dest == \"IAH\") |&gt; \n    arrange(dep_delay) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT flights.*\nFROM flights\nWHERE (dest = 'IAH')\nORDER BY dep_delay\n\nCodeflights |&gt; \n    filter(dest == \"IAH\") |&gt; \n    arrange(dep_delay) |&gt; \n    head(n = 10) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT flights.*\nFROM flights\nWHERE (dest = 'IAH')\nORDER BY dep_delay\nLIMIT 10\n\nCodeflights |&gt; \n    filter(dest == \"IAH\" & origin == \"JFK\") |&gt; \n    arrange(dep_delay) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT flights.*\nFROM flights\nWHERE (dest = 'IAH' AND origin = 'JFK')\nORDER BY dep_delay\n\nCodeflights |&gt; \n    filter(dest == \"IAH\" | origin == \"JFK\") |&gt; \n    arrange(year, month, day, desc(dep_delay)) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT flights.*\nFROM flights\nWHERE (dest = 'IAH' OR origin = 'JFK')\nORDER BY \"year\", \"month\", \"day\", dep_delay DESC\n\n\n\nCodeflights |&gt; \n    filter(dest %in% c(\"IAH\", \"HOU\")) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT flights.*\nFROM flights\nWHERE (dest IN ('IAH', 'HOU'))\n\nCodeflights |&gt; \n    filter(!is.na(dep_delay)) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT flights.*\nFROM flights\nWHERE (NOT((dep_delay IS NULL)))\n\n\n\nCodeplanes |&gt; \n    select(tailnum, type, manufacturer, model, year) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT tailnum, \"type\", manufacturer, model, \"year\"\nFROM planes\n\nCodeplanes |&gt; \n    select(tailnum, type, manufacturer, model, year) |&gt; \n    rename(year_built = year) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT tailnum, \"type\", manufacturer, model, \"year\" AS year_built\nFROM planes\n\n\n\nCodeflights |&gt; \n    mutate(\n        speed = distance / (air_time / 60)\n    ) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT flights.*, distance / (air_time / 60.0) AS speed\nFROM flights\n\n\n\nCodeflights |&gt; \n    left_join(planes, by = \"tailnum\") |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT\n  flights.\"year\" AS \"year.x\",\n  \"month\",\n  \"day\",\n  dep_time,\n  sched_dep_time,\n  dep_delay,\n  arr_time,\n  sched_arr_time,\n  arr_delay,\n  carrier,\n  flight,\n  flights.tailnum AS tailnum,\n  origin,\n  dest,\n  air_time,\n  distance,\n  \"hour\",\n  \"minute\",\n  time_hour,\n  planes.\"year\" AS \"year.y\",\n  \"type\",\n  manufacturer,\n  model,\n  engines,\n  seats,\n  speed,\n  engine\nFROM flights\nLEFT JOIN planes\n  ON (flights.tailnum = planes.tailnum)",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>16 Databases and SQL</span>"
    ]
  },
  {
    "objectID": "src/ica/16-databases-notes.html#sql-practice",
    "href": "src/ica/16-databases-notes.html#sql-practice",
    "title": "16 Databases and SQL",
    "section": "SQL Practice",
    "text": "SQL Practice\nStack Exchange Data Explorer\nWe will experiment with the Stack Exchange Data Explorer, a website that provides a SQL interface for all the data in StackExchange.\nStackExchange powers the StackOverflow programming question and answer site, but it also powers question and answer sites related to 126 topics including English, Travel, Bicycles, and Parenting.\nStackExchange provides an in-depth Data Explorer Tutorial. We start with this interface to construct SQL queries on the Travel Data Explorer.\nInstructions\nHead to the Stack Exchange Data Explorer for Travel.\nYou will see a list of queries other users have created in the past. These queries are for all Stack Exchange sites, so some may not be relevant. Queries about your activity (for example, “How many upvotes do I have for each tag?”) will not be useful either if you do not have activity for the particular site.\nClick on one of them and you see the SQL code for the query.\nThen click the “Run Query” button to get results.\nFor example, you might look at the number of up vs down votes for questions and answers by weekday and notice that for questions, Tuesday has the highest up vs. down vote ratio and Saturday has the lowest. You can contemplate hypotheses for this difference!\nSelect Queries\nLet’s experiment with our own queries.\nClick on “Compose Query” in the upper right, and notice the tables are shown in the right.\nAs a reminder, a table is similar to a data frame.\n\nEach table lists the columns stored within the table and the data types for the columns.\nLook through the tables for Posts, Users, and Comments.\nDo the columns generally make sense, and correspond to the StackOverflow website?\n\nThere’s a description of the tables and columns (called a schema) available on StackExchange’s Meta Q&A Site.\nNow enter your first query in the text box and click the “Run Query” button:\n\nCodeSELECT TOP(100) Id, Title, Score, Body, Tags\nFROM Posts\n\n\nIn this query we already see several important features of SQL:\n\n\nSELECT tells SQL that a query is coming.\n\nTOP(100) only returns the first 100 rows.\n\nNote: The StackExchange data explorer uses a variant of SQL called Transact SQL that is supported by Microsoft databases. TOP(100) is a non-standard SQL feature supported by T-SQL. For most databases you would accomplish the same goal by adding LIMIT 100 to the end of the query.\n\n\n\nId, Title, Score, Body, Tags determines what columns are included in the result\n\nFROM Posts determines the source dataset.\n\nFrom glancing at the results, it appears that this table contains both questions and answers.\nLet’s try to focus on answers.\nLooking again at the Schema Description, notice that there is a PostTypeId column in Posts, and a value of 1 corresponds to questions.\nLet’s update our query to only include questions:\n\nCodeSELECT TOP(100)\nId, Title, Score, Body, Tags\nFROM Posts\nWHERE PostTypeId = 1\n\n\nThe SQL command WHERE is like the filter command we have been using in dplyr.\n\nNote that whereas we used the double equals == for comparison in R, the SQL WHERE command takes just a single =.\n\nExercise: Find the title and score of Posts that have a score of at least 110. Hint: TOP is not necessary here because you want all result rows.\n\nCodeSELECT Title, Score\nFROM Posts\nWHERE PostTypeId = 1 AND Score &gt;= 110\n\n\nExercise: Find posts whose title contains some place you are interested in (you pick!). Hint: use SQL’s LIKE operator.\n\nCodeSELECT Title, Score\nFROM Posts\nWHERE PostTypeId = 1 AND Title LIKE '%Paris%'\n\n\nNote that you can look up the actual webpage for any question using its Id.\nFor example, if the Id is 19591, the webpage URL would be https://travel.stackexchange.com/questions/19591/. Look up a few of the questions by their Id.\nIt’s unclear how the 100 questions we saw were selected from among the over 43,000 total questions.\n\nTo count the number of posts, we can use COUNT in SQL: SELECT COUNT(Id) FROM Posts Where PostTypeId = 1.\n\nLet’s try to arrange the Posts by score.\n\nCodeSELECT TOP(100)\nId, Title, Score, Body, Tags\nFROM Posts\nWHERE PostTypeId = 1\nORDER BY Score DESC\n\n\nThe ORDER BY ??? DESC syntax is similar to R’s arrange(). You can leave off the DESC if you want the results ordered smallest to largest.\nWe could also find the highest rated questions tagged “italy”:\n\nCodeSELECT TOP(100)\nId, Title, Score, Body, Tags\nFROM Posts\nWHERE PostTypeId = 1 AND Tags LIKE '%italy%'\nORDER BY Score DESC\n\n\nExercise: Pick two tags that interest you and you think will occur together and find the top voted posts that contain both.\n\nCodeSELECT Title, Score, Tags\nFROM Posts\n\n\n\nCodeWHERE PostTypeId = 1 AND Tags LIKE '%paris%' AND Tags LIKE '%france%'\n\n\nSQL Summarization\nSo far, we have covered the equivalent of R’s selecting, filtering, and arranging.\nLet’s take a look at grouping and summarizing now, which has similar structures in both R and SQL. Imagine we want to see how many posts of each type there are. This query shows us that there are 44K questions and 71K answers.\n\nCodeSELECT \nPostTypeId, COUNT(Id) numPosts\nFROM posts\nGROUP BY PostTypeId \nORDER BY PostTypeId\n\n\nNote two characteristics of SQL summarization here:\n\nThe GROUP BYclause indicates the table column for grouping, much like R’s group_by.\nThere is no explicit summarize. Instead, all columns that appear in the SELECT except for those listed in GROUP BY must make use of an aggregate function. COUNT(*) is one of these, and is the equivalent of R’s n(). Many other aggregate functions exist, including MAX, SUM, AVG, and many others. Every aggregate function requires a column as an argument (even COUNT() which doesn’t logically need one).\nThe aggregate column (in this case COUNT(Id)) must immediately be followed by a name that will be used for it in the results (in this case numPosts). This can be particularly useful if you want to order by the aggregated value.\n\nExercise: Change the previous query so it orders the result rows by the number of posts of that type. Hint: Reuse the name you assigned to the aggregate function.\n\nCodeSELECT \nPostTypeId, COUNT(Id) numPosts\nFROM posts\nGROUP BY PostTypeId \nORDER BY numPosts\n\n\nExercise: Find the most commonly used tagsets (sets/combinations of tags) applied to posts. Note that this is not asking you to count the most common individual tags — this would be more complex because multiple tags are squashed into the Tags field.\n\nCodeSELECT\nTags, COUNT(Tags) numTagsets\nFROM posts\nGROUP BY Tags\nORDER BY numTagsets\n\n\nSQL Joins\nFinally, as with R, we often want to join data from two or more tables. The types of joins in SQL are the same as we saw with R (inner, outer, left, right). Most commonly we want to perform an INNER join, which is the default if you just say JOIN. (We can look up the inner_join() documentation to remind ourselves what an inner join does.)\nLet’s say we wanted to enhance the earlier query to find the highest scoring answers with some information about each user.\n\nCodeSELECT TOP(100)\nTitle, Score, DisplayName, Reputation\nFROM Posts p\nJOIN Users u\nON p.OwnerUserId = u.Id\nWHERE PostTypeId = 1\nORDER BY Score Desc\n\n\nWe see a few notable items here:\n\nThe JOIN keyword must go in between the two tables we want to join.\nEach table must be named. In this case we named posts p and users u.\nWe need to specify the relationship that joins the two tables. In this case, a posts OwnerUserId column refers to the Id column in the users table.\n\nExercise: Create a query similar to the one above that identifies the authors of the top rated comments instead of posts.\n\nCodeSELECT TOP(100)\nText, Score, DisplayName, Reputation, AboutMe, Views, UpVotes, DownVotes\nFROM Comments c\nJOIN Users u\nON c.UserId = u.Id\nORDER BY Score Desc\n\n\nIf you want more practice, go to https://mystery.knightlab.com/.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>16 Databases and SQL</span>"
    ]
  },
  {
    "objectID": "src/ica/16-databases-notes.html#going-beyond",
    "href": "src/ica/16-databases-notes.html#going-beyond",
    "title": "16 Databases and SQL",
    "section": "Going Beyond",
    "text": "Going Beyond\nExploring cloud DBMS’s\nRedshift is Amazon’s cloud database management system (DBMS).\n\nTo try out Redshift, you can sign up for a free AWS Educate account. Once your account is confirmed, you will have access to many tutorials about cloud computing.\nIn the Getting Started section of your AWS Educate main page, navigate to the Getting Started with Databases (Lab) tutorial on the second page of tutorials.\nVarious Redshift resources can be found here.\n\nBigQuery is Google’s DBMS.\n\nBigQuery can be tried for free through Big Query sandbox.\nOn the main BigQuery page you’ll see a big blue button that says “Try BigQuery free”.\nOn the cloud welcome page under the Products section, you’ll see a button for “Analyze and manage data - BigQuery”.\nAccessing public data within BigQuery\n\nIn your “Welcome to BigQuery Studio!” window, you’ll see a “Try the Google Trends Demo Query” section.\nClick the “Open this query” blue button to get an example SQL statement for the Google Trends dataset. You’ll also see on the left panel a list of all public datasets available through BigQuery. ## Done!\n\n\nCheck the ICA Instructions for how to (a) push your code to GitHub and (b) update your portfolio website",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>16 Databases and SQL</span>"
    ]
  },
  {
    "objectID": "src/appx/appx-sample1.html",
    "href": "src/appx/appx-sample1.html",
    "title": "Appendix A — Appendix Sample 1",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendix Sample 1</span>"
    ]
  },
  {
    "objectID": "src/appx/appx-sample2.html",
    "href": "src/appx/appx-sample2.html",
    "title": "Appendix B — Appendix Sample 2",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix Sample 2</span>"
    ]
  }
]